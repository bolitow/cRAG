from src.retrieval.retriever import BaseRetriever
from src.retrieval.embedder import DocumentEmbedder
from src.grading.knowledge_stripper import KnowledgeStripper
from src.grading.relevance_grader import RelevanceGrader
from src.refinement.knowledge_refiner import KnowledgeRefiner

# Initialisation de tous les composants
embedder = DocumentEmbedder()
retriever = BaseRetriever(embedder)
stripper = KnowledgeStripper()
grader = RelevanceGrader(model_name='google/gemma-3-4b-it', use_llm=True, embedder=embedder)
# Dans test_knowledge_refiner.py
refiner = KnowledgeRefiner(
    relevance_threshold=0.5,
    similarity_threshold=0.85,
    max_strips=7,
    min_coverage=0.7,
    embedder=embedder
)

# Documents de test enrichis
documents = [
    """Les transformers sont une architecture de rÃ©seau de neurones introduite en 2017.
    Ils utilisent le mÃ©canisme d'attention pour traiter les sÃ©quences.
    L'attention permet au modÃ¨le de se concentrer sur diffÃ©rentes parties de l'entrÃ©e.
    Cette architecture a rÃ©volutionnÃ© le traitement du langage naturel.""",

    """L'attention est le mÃ©canisme clÃ© des transformers. Elle calcule des scores
    entre tous les Ã©lÃ©ments d'une sÃ©quence. Les transformers utilisent l'attention
    multi-tÃªtes pour capturer diffÃ©rents types de relations. C'est ce qui leur
    permet de comprendre le contexte global.""",

    """BERT utilise l'architecture transformer de maniÃ¨re bidirectionnelle.
    GPT utilise les transformers de maniÃ¨re autoregressive.
    Les deux modÃ¨les ont montrÃ© des performances exceptionnelles.
    Les transformers permettent le traitement parallÃ¨le des sÃ©quences.""",

    """Les composants principaux des transformers incluent :
    - Les couches d'attention multi-tÃªtes
    - Les rÃ©seaux feed-forward
    - La normalisation par couches
    - Les connexions rÃ©siduelles
    Ces Ã©lÃ©ments travaillent ensemble pour traiter l'information.""",

    # Ajoutons du bruit
    """Les rÃ©seaux de neurones convolutifs sont excellents pour la vision.
    Ils utilisent des filtres pour dÃ©tecter des caractÃ©ristiques.
    Les CNN ont dominÃ© la vision par ordinateur pendant des annÃ©es."""
]

# Indexer les documents
retriever.index_documents(documents)

# RequÃªte test
query = "Comment fonctionnent les transformers ?"

print("=== PIPELINE CRAG COMPLET ===\n")

# Ã‰tape 1 : Retrieval
print("1ï¸âƒ£ RETRIEVAL")
retrieved_docs = retriever.retrieve(query, k=5)
print(f"   Documents rÃ©cupÃ©rÃ©s : {len(retrieved_docs)}")

# Ã‰tape 2 : Knowledge Stripping
print("\n2ï¸âƒ£ KNOWLEDGE STRIPPING")
all_strips = []
for doc in retrieved_docs:
    strips = stripper.strip_document(doc['text'], doc['index'])
    all_strips.extend(strips)
print(f"   Strips extraits : {len(all_strips)}")

# Ã‰tape 3 : Relevance Grading
print("\n3ï¸âƒ£ RELEVANCE GRADING")
graded_strips = grader.grade_strips(query, all_strips)
print(f"   Strips gradÃ©s :")
for i, gs in enumerate(graded_strips[:5]):
    print(f"   - {gs.relevance_category.name}: {gs.strip.content[:50]}...")

# Ã‰tape 4 : Knowledge Refinement
print("\n4ï¸âƒ£ KNOWLEDGE REFINEMENT")
refined_knowledge = refiner.refine_knowledge(graded_strips, query)

print(f"\nðŸ“Š RÃ‰SULTATS DU RAFFINEMENT :")
print(f"   {refined_knowledge.summary}")

print(f"\nðŸ“‹ STRIPS FINAUX ORGANISÃ‰S :")
for i, strip in enumerate(refined_knowledge.strips):
    print(f"\n   {i + 1}. [{strip.strip.strip_type}] Score: {strip.relevance_score:.3f}")
    print(f"      {strip.strip.content[:80]}...")

if refined_knowledge.missing_aspects:
    print(f"\nâš ï¸  ASPECTS MANQUANTS : {', '.join(refined_knowledge.missing_aspects)}")

if refined_knowledge.needs_additional_search:
    print("\nðŸ” RECOMMANDATION : Effectuer une recherche supplÃ©mentaire")
    print("   Raisons possibles :")
    print("   - Couverture insuffisante des aspects requis")
    print("   - Manque d'informations sur le mÃ©canisme dÃ©taillÃ©")
else:
    print("\nâœ… CONTEXTE SUFFISANT : PrÃªt pour la gÃ©nÃ©ration de rÃ©ponse")

# Afficher le contexte final qui serait envoyÃ© au LLM
print("\nðŸ“ CONTEXTE POUR LA GÃ‰NÃ‰RATION :")
print("-" * 50)
context = "\n\n".join([strip.strip.content for strip in refined_knowledge.strips])
print(context[:500] + "..." if len(context) > 500 else context)